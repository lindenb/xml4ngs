#parse("common.vm")
#parse("sample.vm")
#parse("fastq.vm")
#parse("pair.vm")
#parse("sample.vm")
#parse("varkit.vm")
#parse("gatk.vm")
## PROXY SETTING 
#if($project.propertyMap.containsKey("http.proxy.host")
)#set($set_curl_proxy= " --proxy "+$project.propertyMap["http.proxy.host"]+":"+$project.propertyMap["http.proxy.port"])#set($set_jvm_proxy= " -Dhttp.proxyHost="+$project.propertyMap["http.proxy.host"]+" -Dhttp.proxyPort="+$project.propertyMap["http.proxy.port"])#else#set($set_curl_proxy ="")#set($set_jvm_proxy ="")#end


#
# Makefile for NGS
#
# WWW: https://github.com/lindenb/xml4ngs
#
# Date : $now
#




#
# this is the name of the current Makefile
# should be always here,  before' include'
# will be used for 'git'
#
makefile.name := $(lastword $(MAKEFILE_LIST))

#
# tools.mk define the path to the application
# config.mk are user-specific values
#
include tools.mk

############################################
#
# PROPERTIES defined in the project.xml 
#
#
#foreach($p in $project.properties.property)
# ${p.key}=${p.value.replaceAll("\n"," ")}
#end

#
# OUTPUT DIRECTORY
#

#if(! $project.propertyMap.containsKey("output.directory") )
${utils.error("output.directory' undefined in project.")}
#end
OUTDIR=$project.propertyMap["output.directory"]

#
# LIST_OF_PHONY_TARGET
#
LIST_PHONY_TARGET=


#
# fix PATH (tophat needs this)
#
export PATH:=$(PATH):${BOWTIE2.dir}:${samtools.dir}:${CUFFLINKS.dir}:${R.dir}/bin:/usr/bin

###
# FIX LOCALE (http://unix.stackexchange.com/questions/61985)
#
export LC_ALL:=C


#
#
# path to GHOSTVIEW
GHOSTVIEW ?= gs



TABIX.bgzip?=${TABIX}/bgzip
TABIX.tabix?=${TABIX}/tabix



#if(! $project.propertyMap.containsKey("genome.reference.path") )
${utils.error("genome.reference.path' undefined in project.")}
#end

#
# reference genome was set in project properties
#
REF=$project.propertyMap["genome.reference.path"]
INDEXED_REFERENCE=$(foreach S,.amb .ann .bwt .pac .sa .fai,$(addsuffix $S,$(REF))) $(addsuffix	.dict,$(basename $(REF)))

#
# min mapping quality
#
#if(! $project.propertyMap.containsKey("min.mapping.quality") )
${utils.warning("'min.mapping.quality' undefined in project, will use: 30")}
MIN_MAPPING_QUALITY=30
#else
MIN_MAPPING_QUALITY=$project.propertyMap["min.mapping.quality"]
#end



#
# file that will be used to lock the SQL-related resources
#
LOCKFILE=$(OUTDIR)/_tmp.${project.generateId}.lock
XMLSTATS=$(OUTDIR)/pipeline.stats.xml
HSQLSTATS=$(OUTDIR)/hsqldb.stats




SAMPLES=#foreach($sample in $project.sample)${sample.name} #end


#if(! $project.propertyMap.containsKey("capture.bed.path") )
${utils.warning("'capture.bed.path' undefined in project.")}
capture.bed=$(OUTDIR)/ensembl.exons.bed
#else
capture.bed=${project.propertyMap["capture.bed.path"]}
#end


#if(! $project.propertyMap.containsKey("snpEff.build") )
SNPEFFBUILD=hg19
#else
SNPEFFBUILD=${project.propertyMap["snpEff.build"]}
#end


#if(! $project.propertyMap.containsKey("known.sites") )
${utils.error("'known.sites' undefined in project.")}
#else
known.sites=${project.propertyMap["known.sites"]}
#end


#
# TARGETS AS LISTS
#

##########################################################################################################
#
# PHONY TARGETS
#
#
.PHONY: all toptarget ${LIST_PHONY_TARGET} 

##########################################################################################################
#
# MACRO DEFINITIONS
#
#
ifndef DELETEFILE
DELETEFILE=echo 
endif

define bai_files
    $(foreach B,$(filter %.bam,$(1)),  $(addsuffix .bai,$B) )
endef


define indexed_bam
    $(1) $(call bai_files, $(1))
endef

define create_symbolic_link
	cp -f $(1) $(2)
endef

define notempty
    test -s $(1) || (echo "$(1) is empty" && rm -f $(1) && exit -1) 
endef

define check_no_sge
	if  [ "${JOB_ID}" != "" ]; then echo "This process shouldn't be run with SGE. Please invoke the regular make." ; exit -1;  fi
endef



CREATE_HSQLDB_DATABASE=create table if not exists begindb(file varchar(255) not null,category varchar(255) not null,w TIMESTAMP,CONSTRAINT K1 UNIQUE (file,category));create table if not exists enddb(file varchar(255) not null,category varchar(255) not null,w TIMESTAMP,CONSTRAINT K2 UNIQUE (file,category));create table if not exists sizedb(file varchar(255) not null,size BIGINT,CONSTRAINT K3 UNIQUE (file));

define timebegindb
	lockfile $(LOCKFILE)
	$(JAVA) -jar ${HSQLDB.sqltool} --autoCommit --inlineRc=url=jdbc:hsqldb:file:$(HSQLSTATS) --sql "$(CREATE_HSQLDB_DATABASE) delete from begindb where file='$(1)' and category='$(2)'; insert into begindb(file,category,w) values ('$(1)','$(2)',NOW);"
	rm -f $(LOCKFILE)
endef

define timeenddb
	lockfile $(LOCKFILE)
	$(JAVA) -jar ${HSQLDB.sqltool} --autoCommit --inlineRc=url=jdbc:hsqldb:file:$(HSQLSTATS) --sql "$(CREATE_HSQLDB_DATABASE) delete from enddb where file='$(1)' and category='$(2)'; insert into enddb(file,category,w) values ('$(1)','$(2)',NOW);"
	rm -f $(LOCKFILE)
endef


define sizedb
	stat -c "%s" $(1) | while read L; do lockfile $(LOCKFILE); $(JAVA) -jar ${HSQLDB.sqltool} --autoCommit --inlineRc=url=jdbc:hsqldb:file:$(HSQLSTATS) --sql "$(CREATE_HSQLDB_DATABASE) delete from sizedb where file='$(1)'; insert into sizedb(file,size) values('$(1)','\$\$L');" ; rm -f $(LOCKFILE);done
endef




define delete_and_touch
	
endef

##########################################################################################################
#
# PATTERN RULES DEFINITIONS
#
#

#macro(call_index_genome_rules $extension)


#index with bwa
%.amb %.ann %.bwt %.pac %.sa : %$extension
	$(BWA) index -a bwtsw $<

#index with samtools
${extension}.fai : %$extension
	$(SAMTOOLS) faidx $<

#picard dictionnary
%.dict: %${extension}
	 $(JAVA) -jar $(PICARD)/CreateSequenceDictionary.jar \
		R=$< \
		O=$@ \
		GENOME_ASSEMBLY=$(basename $(notdir $<)) \
		TRUNCATE_NAMES_AT_WHITESPACE=true

#end
#call_index_genome_rules(".fa")
#call_index_genome_rules(".fasta")

#
# treat all files as SECONDARY
#
.SECONDARY :



toptarget:
	@echo "This is the top target. Please select a specific target"
	@echo "e.g: ${LIST_PHONY_TARGET} "

all: ${LIST_PHONY_TARGET} all_predictions fastx hsqldb_statistics 

indexed_reference: $(INDEXED_REFERENCE)







LIST_PHONY_TARGET+= bams_realigned 
bams_realigned:#foreach($sample in $project.sample) #sample_realigned($sample) #end

LIST_PHONY_TARGET+= bams_markdup 
bams_markdup: #foreach($sample in $project.sample) #sample_markdup($sample) #end

LIST_PHONY_TARGET+= bams_merged 
bams_merged: #foreach($sample in $project.sample) #sample_merged($sample) #end

LIST_PHONY_TARGET+= bams_recalibrated 
bams_recalibrated: #foreach($sample in $project.sample) #sample_recal($sample) #end

LIST_PHONY_TARGET+= bams_unsorted 
bams_unsorted: #foreach($sample in $project.sample) #foreach($pair in $sample.sequences.pair)#pair_bam_unsorted($pair)#end#end

LIST_PHONY_TARGET+= bams_sorted 
bams_sorted: #foreach($sample in $project.sample) #foreach($pair in $sample.sequences.pair)#pair_bam_sorted($pair) #end#end

LIST_PHONY_TARGET+= coverage
coverage:$(OUTDIR)/mean_coverage01.pdf
$(OUTDIR)/mean_coverage01.pdf: $(addsuffix .sample_summary, #foreach($sample in $project.sample)#sample_distribution_of_coverage_recal($sample)#end)
	echo "sample	mean-coverage" > $(patsubst %.pdf,%.tsv,$@)
	cat $^ | sort | grep -v -E  '^(Total|sample_id)'  |\
		cut -d '	' -f1,3 >> $(patsubst %.pdf,%.tsv,$@)
	echo 'pdf("$@",paper="A4r"); T&lt;-read.table("$(patsubst %.pdf,%.tsv,$@)",header=T,sep="\t",row.names=1); barplot(as.matrix(t(T)),legend=colnames(T),beside=TRUE,col=rainbow(7),las=2,cex.names=0.8); dev.off()' |\
	${R.exe} --no-save
	



############################################################################################
#
# ALLELES CALLING
#
#
#macro(call_with_samtools_mpileup)	$(call timebegindb,$@,mpileup)
	$(SAMTOOLS) mpileup #if($project.propertyMap["is.haloplex"]=="yes") -A  -d 8000 #end -uD \
		-q $(MIN_MAPPING_QUALITY) \
		#if($project.propertyMap["allele.calling.in.capture"]=="yes") -l $(OUTDIR)/capture500.bed #end \
		-f $(REF) $(filter %.bam,$^) |\
	$(BCFTOOLS) view -vcg - |\
	$(TABIX.bgzip) -c > $@
	$(TABIX.tabix) -p vcf $@ 
	@$(call timeenddb,$@,mpileup)
	@$(call sizedb,$@)
	$(call notempty,$@)

#end


#macro(call_with_gatk)		$(call timebegindb,$@,UnifiedGenotyper)
	$(JAVA) $(GATK.jvm) -jar $(GATK.jar) $(GATK.flags) \
		-R $(REF) \
		-T UnifiedGenotyper \
		-glm BOTH \
		-S SILENT \
		#if($project.propertyMap.containsKey("gatk.unified.genotyper.options")
			) ${project.propertyMap["gatk.unified.genotyper.options"]} #end \
		#if($project.propertyMap["allele.calling.in.capture"]=="yes") -L $(OUTDIR)/capture500.bed #end \
		$(foreach B,$(filter %.bam,$^), -I $B ) \
		--dbsnp:vcfinput,VCF $(known.sites) \
		-o $(basename $@)
	$(TABIX.bgzip) -f $(basename $@)
	@$(call timeendb,$@,UnifiedGenotyper)
	@$(call sizedb,$@)
	$(call notempty,$@)

#end




#if( $project.propertyMap["one.vcf.per.sample"]=="yes")

LIST_PHONY_TARGET+= all_predictions
all_predictions: \
	variations.samtools \
	variations.gatk \
	variations.samtools.snpeff \
	variations.gatk.snpeff \
	variations.samtools.vep \
	variations.gatk.vep


LIST_PHONY_TARGET+= variations.samtools 
variations.samtools: #foreach($sample in $project.sample) #sample_vcf_samtools($sample) #end
LIST_PHONY_TARGET+= variations.gatk 
variations.gatk: #foreach($sample in $project.sample) #sample_vcf_gatk($sample) #end


LIST_PHONY_TARGET+= variations.samtools.snpeff 
variations.samtools.snpeff: #foreach($sample in $project.sample) #sample_vcf_samtools_snpeff($sample) #end

LIST_PHONY_TARGET+= variations.gatk.snpeff  
variations.gatk.snpeff: #foreach($sample in $project.sample) #sample_vcf_gatk_snpeff($sample) #end

LIST_PHONY_TARGET+= variations.samtools.vep  
variations.samtools.vep: #foreach($sample in $project.sample) #sample_vcf_samtools_vep($sample) #end

LIST_PHONY_TARGET+= variations.gatk.vep  
variations.gatk.vep: #foreach($sample in $project.sample) #sample_vcf_gatk_vep($sample) #end



#foreach($sample in $project.sample)


#
# prediction samtools with Variation Ensembl Prediction API for  sample ${sample.name}
#

#set($filterparam=${project.propertyMap["samtools.vcf.filtration"]}+" "+${project.propertyMap["vep.vcf.filtration"]})
#annotate_with_vep(
	"#sample_vcf_samtools_vep($sample)"
	"#sample_vcf_samtools($sample)"
	"mpileupvep"
	"$filterparam"
	)


#
# prediction gatk with Variation Ensembl Prediction API for  sample ${sample.name}
#
#set($filterparam=${project.propertyMap["gatk.vcf.filtration"]}+" "+${project.propertyMap["vep.vcf.filtration"]})

#annotate_with_vep(
	"#sample_vcf_gatk_vep($sample)"
	"#sample_vcf_gatk($sample)"
	"gatkvep"
	"$filterparam"
	)





#
# Annotation samtools with SNPEFF for  sample ${sample.name}
#
#set($filterparam=${project.propertyMap["samtools.vcf.filtration"]}+" "+${project.propertyMap["snpeff.vcf.filtration"]})
#annotate_with_snpeff(
	"#sample_vcf_samtools_snpeff($sample)"
	"#sample_vcf_samtools($sample)"
	"mpileupsnpeff"
	"$filterparam"
	)


#
# Annotation gatk with SNPEFF for  sample ${sample.name}
#
#set($filterparam=${project.propertyMap["gatk.vcf.filtration"]}+" "+${project.propertyMap["snpeff.vcf.filtration"]})
#annotate_with_snpeff(
	"#sample_vcf_gatk_snpeff($sample)"
	"#sample_vcf_gatk($sample)"
	"gatksnpeff"
	"$filterparam"
	)


#
# Allele calling with samtools for sample ${sample.name}
#
#sample_vcf_samtools($sample) : #if($project.propertyMap["allele.calling.in.capture"]=="yes") $(OUTDIR)/capture500.bed #end  $(call indexed_bam,#sample_recal($sample) )
#call_with_samtools_mpileup()

#
# Allele calling with GATK for sample <xsl:value-of select="@name"/>
#
#sample_vcf_gatk($sample): #if($project.propertyMap["allele.calling.in.capture"]=="yes") $(OUTDIR)/capture500.bed #end  $(call indexed_bam,#sample_recal($sample)) $(known.sites)
#call_with_gatk()

#end

## end for each sample

#else

LIST_PHONY_TARGET+=all_predictions 
all_predictions: \
	$(OUTDIR)/variations.samtools.vep.vcf.gz \
	$(OUTDIR)/variations.samtools.snpEff.vcf.gz \
	$(OUTDIR)/variations.gatk.vep.vcf.gz \
	$(OUTDIR)/variations.gatk.snpEff.vcf.gz 
	
#
# prediction samtools with Variation Ensembl Prediction API
#
#set($filterparam=${project.propertyMap["samtools.vcf.filtration"]}+" "+${project.propertyMap["vep.vcf.filtration"]})
#annotate_with_vep(
	"$(OUTDIR)/variations.samtools.vep.vcf.gz"
	"$(OUTDIR)/variations.samtools.vcf.gz"
	"samtoolsvep"
	"$filterparam"
	)

#
# prediction gatk with Variation Ensembl Prediction API
#
#set($filterparam=${project.propertyMap["gatk.vcf.filtration"]}+" "+${project.propertyMap["vep.vcf.filtration"]})
#annotate_with_vep(
	"$(OUTDIR)/variations.gatk.vep.vcf.gz"
	"$(OUTDIR)/variations.gatk.vcf.gz"
	"gatkvep"
	"$filterparam"
	)

#
# annotate samtools vcf with snpEff
#
#set($filterparam=${project.propertyMap["samtools.vcf.filtration"]}+" "+${project.propertyMap["snpeff.vcf.filtration"]})
#annotate_with_snpeff(
	"$(OUTDIR)/variations.samtools.snpEff.vcf.gz"
	"$(OUTDIR)/variations.samtools.vcf.gz"
	"mpileupsnpeff"
	"$filterparam"
	)

#
# annotate GATK vcf with snpEff
#
#set($filterparam=${project.propertyMap["gatk.vcf.filtration"]}+" "+${project.propertyMap["snpeff.vcf.filtration"]})
#annotate_with_snpeff(
	"$(OUTDIR)/variations.gatk.snpEff.vcf.gz"
	"$(OUTDIR)/variations.gatk.vcf.gz"
	"gatksnpeff"
	"$filterparam"
	)

#
# Allele calling with samtools
#
$(OUTDIR)/variations.samtools.vcf.gz: #if($project.propertyMap["allele.calling.in.capture"]=="yes") $(OUTDIR)/capture500.bed #end  $(call indexed_bam,#foreach($sample in $project.sample) #sample_recal($sample)  #end)
#call_with_samtools_mpileup()

#
# Allele calling with GATK
#
$(OUTDIR)/variations.gatk.vcf.gz: #if($project.propertyMap["allele.calling.in.capture"]=="yes") $(OUTDIR)/capture500.bed #end  $(call indexed_bam,#foreach($sample in $project.sample) #sample_recal($sample)  #end ) $(known.sites)
#call_with_gatk()

#end


############################################################################################
#
# Statistics for BAM
#
LIST_PHONY_TARGET+= bam_statistics 
bam_statistics: $(OUTDIR)/bamstats01.pdf $(OUTDIR)/bamstats03.pdf $(OUTDIR)/bamstats04.tsv beddepth coverage_distribution 


LIST_PHONY_TARGET+= beddepth
beddepth:  #foreach($sample in $project.sample) #sample_beddepth(${sample}) #end

#
# create a PDF for bamstats01.tsv
#
$(OUTDIR)/bamstats01.pdf : $(OUTDIR)/bamstats01.tsv
	echo 'pdf("$@",paper="A4r"); T&lt;-read.delim("$<",header=T,sep="\t",row.names=1);barplot(as.matrix(t(T)),beside=TRUE,col=rainbow(8),las=2,cex.names=0.8,legend=colnames(T)); dev.off()' |\
	${R.exe} --no-save

#
# count of mapped-reads	
#
$(OUTDIR)/bamstats01.tsv : #foreach($sample in $project.sample) #sample_bamstat01_tsv($sample) #end
	cat $^ |  LC_ALL=C sort -t '	' -k1,1 | uniq > $@


#
# count of distribution of coverage
#
$(OUTDIR)/bamstats04.tsv : #foreach($sample in $project.sample)  #sample_bamstat04_tsv($sample) #end
	cat $^ |  LC_ALL=C sort -t '	' -k1,1 | uniq > $@




## coverage of distribution ############################################################################################

LIST_PHONY_TARGET+= coverage_distribution

coverage_distribution:  $(OUTDIR)/all.distribution.recal.pdf



$(OUTDIR)/all.distribution.recal.pdf : #foreach($sample in $project.sample) #sample_distribution_of_coverage_recal($sample) #end
	gs -dBATCH -dNOPAUSE -q -sDEVICE=pdfwrite -sOutputFile=$@ $(filter %.pdf,$^)


#
# create a PDF for bamstats03.tsv
#
$(OUTDIR)/bamstats03.pdf : $(OUTDIR)/bamstats03.tsv
	echo 'pdf("$@",paper="A4r"); T<-read.delim("$<",header=T,sep="\t",row.names=1);barplot(as.matrix(t(T)),beside=TRUE,col=rainbow(7),las=2,cex.names=0.8,legend=colnames(T)); dev.off()' |\
	${R.exe} --no-save

#
# count of mapped-reads, quality per sample	
#
$(OUTDIR)/bamstats03.tsv : $(call indexed_bam,#foreach($sample in $project.sample) #sample_recal($sample) #end)  $(capture.bed) 
	@$(call timebegindb,$@,$@)
	${VARKIT}/bamstats03 -b $(capture.bed) $(filter %.bam,$^) | awk -F '/' '{print \$\$NF;}'  | sort  > $@
	@$(call timeendb,$@,$@)
	@$(call sizedb,$@)
	$(call notempty,$@)


##############################################################"
#
# Capture
#

$(OUTDIR)/ensembl.exons.bed:
	$(call timebegindb,$@,$@)
	curl ${set_curl_proxy} -d 'query=<![CDATA[<?xml version="1.0" encoding="UTF-8"?><Query virtualSchemaName="default" formatter="TSV" header="0" uniqueRows="0" count="" datasetConfigVersion="0.6" ><Dataset name="#if($project.propertyMap.containsKey["ensembl.dataset.name"])
		)${project.propertyMap["ensembl.dataset.name"]}#{else}hsapiens_gene_ensembl#end" interface="default" ><Attribute name="chromosome_name" /><Attribute name="exon_chrom_start" /><Attribute name="exon_chrom_end" /></Dataset></Query>' "http://www.biomart.org/biomart/martservice/result" |\
	grep -v '_' |grep -v 'GL' |grep -v 'MT' |\
	awk -F '	' '(int($$2) < int($$3))' |\
	uniq | LC_ALL=C sort -t '	' -k1,1 -k2,2n -k3,3n |\
	$(BEDTOOLS)/mergeBed -i - | uniq > $@
	$(call timeendb,$@,$@)
	$(call sizedb,$@)
	$(call notempty,$@)


#
# extends the bed by 500 by default
#
ifndef extend.bed
extend.bed=500
endif


#
# an extended version of the capture, will be used for recalibration
#
$(OUTDIR)/capture500.bed: $(capture.bed)
	cut -d '	' -f1,2,3 $< |\
	awk -F '	'  -v x=$(extend.bed) '{S=int($$2)-int(x); if(S<0) S=0; printf("%s\t%d\t%d\n",$$1,S,int($$3)+int(x));}' |\
	sort -t '	' -k1,1 -k2,2n -k3,3n |\
	$(BEDTOOLS)/mergeBed -d $(extend.bed) -i - > $@
	$(call notempty,$@)


##############################################################################
#
# BEGIN SAMPLES
#
##############################################################################
#foreach($sample in $project.sample)


##############################################################################
#
# BEGIN SAMPLES ${sample.name}
#
##############################################################################


#
# Depth of coverage with GATK
#
$(addsuffix .sample_summary,#sample_coverage($sample) ) : $(call indexed_bam, #sample_recal( ${sample} ) ) $(capture.bed)
	$(call timebegindb,#sample_coverage(${sample}),coverage.gatk)
	$(JAVA) $(GATK.jvm) -jar $(GATK.jar) $(GATK.flags) \
		-R $(REF) \
		-T DepthOfCoverage \
		-L $(filter %.bed,$^) \
		-S SILENT \
		--minMappingQuality $(MIN_MAPPING_QUALITY) \
		-omitBaseOutput \
		--summaryCoverageThreshold 5 \
		-I $(filter %.bam,$^) \
		-o #sample_coverage(${sample}) 
	
	$(call timeendb,#sample_coverage(${sample}),coverage.gatk)



#make_bam_index( "#sample_realigned( $sample )" )

#make_bam_index( "#sample_markdup( $sample )" )

#make_bam_index( "#sample_recal( $sample )" )

#if( $sample.sequences.pair.size() > 1 )
#make_bam_index("#sample_merged($sample)")
#end


#
#
# Recalibrate alignments for Sample ${sample.name}
#
#
LIST_BAM_RECAL+=#sample_recal( ${sample} )
#if( $project.propertyMap["disable.recalibration"]=="yes")

#sample_recal( ${sample} )  : $(call indexed_bam, #sample_markdup( ${sample} ))
	#just create a symbolic link
	$(call create_symbolic_link,$(filter %.bam,$^),$@)
	##ln -s --force $(filter %.bai,$^) $(addsuffix .bai,$@)

#else

#sample_recal( ${sample} )  : $(call indexed_bam, #sample_markdup(${sample}) ) $(OUTDIR)/capture500.bed $(known.sites)
	@$(call timebegindb,$@_countCovariates,covariates)
	$(JAVA) $(GATK.jvm) -jar $(GATK.jar) $(GATK.flags) \
		-T BaseRecalibrator \
		-R $(REF) \
		-I $(filter %.bam,$^) \
		-l INFO \
		#if( $project.propertyMap.containsKey("gatk.base.recalibrator.options")
			) ${project.propertyMap["gatk.base.recalibrator.options"]} #end \
		-o $@.recal_data.grp \
		-knownSites:vcfinput,VCF $(known.sites) \
		-L $(filter %.bed,$^) \
		-cov ReadGroupCovariate \
		-cov QualityScoreCovariate \
		-cov CycleCovariate \
		-cov ContextCovariate
	@$(call timeenddb,$@_countCovariates,covariates)
	@$(call timebegindb,$@_tableRecalibaration,recalibration)
	$(JAVA) $(GATK.jvm) -jar $(GATK.jar) $(GATK.flags) \
		-T PrintReads \
		--disable_bam_indexing \
		-R $(REF) \
		-BQSR $@.recal_data.grp \
		-I $(filter %.bam,$^) \
		#if( $project.propertyMap.containsKey("gatk.recalibration.print.reads.options")
			) ${project.propertyMap["gatk.recalibration.print.reads.options"]} #end \
		-o $@ \
		-l INFO
	@$(call timeenddb,$@_tableRecalibaration,recalibration)
	@$(call sizedb,$@)
	rm -f $@.recal_data.grp
	$(call notempty,$@)
	$(call delete_and_touch,$(filter %.bam,$^) )
	$(call delete_and_touch,$(filter %.bai,$^) )
	touch $@

#end

#
#
# Mark duplicates for Sample: ${sample.name}
#
LIST_BAM_MARKDUP+=#sample_markdup(${sample})

#sample_markdup(${sample}) : $(call indexed_bam, #sample_realigned(${sample}) )
#if(${project.propertyMap["disable.mark.duplicates"]}=="yes" || ${project.propertyMap["is.haloplex"]}=="yes")
	#just create a symbolic link ${utils.warning("Mark Duplicate Disabled")}
	$(call create_symbolic_link,$(filter %.bam,$^),$@)
	# ln -s --force $(filter %.bai,$^) $(addsuffix .bai,$@)
	
#elseif( ${project.propertyMap["use.samtools.rmdup"]} == "yes" )	@$(call timebegindb,$@_markdup,markdup)
	$(SAMTOOLS) rmdup $(filter %.bam,$^) $@
	$(call sizedb,$@)
	$(call notempty,$@)
	$(call delete_and_touch,$(filter %.bam,$^) )
	$(call delete_and_touch,$(filter %.bai,$^) )

#else	$(call timebegindb,$@_markdup,markdup)
	mkdir -p $(addsuffix tmp.rmdup,$(dir $@))
	$(JAVA) $(PICARD.jvm) -jar $(PICARD)/MarkDuplicates.jar \
		TMP_DIR=$(addsuffix tmp.rmdup,$(dir $@)) \
		INPUT=$(filter %.bam,$^) \
		O=$@ \
		MAX_FILE_HANDLES=400 \
		M=$@.metrics \
		AS=true \
		#if(${project.propertyMap.containsKey("picard.mark.duplicates.options")}
			) ${project.propertyMap.get("picard.mark.duplicates.options")} #end \
		VALIDATION_STRINGENCY=SILENT
	@$(call timeenddb,$@_markdup,markdup)
	@$(call sizedb,$@)
	$(call notempty,$@)
	$(call delete_and_touch,$(filter %.bam,$^) )
	$(call delete_and_touch,$(filter %.bai,$^) )
	touch $@

#end

#
#
# IndelRealignments for Sample ${sample.name}
#
#
LIST_BAM_REALIGN+= #sample_realigned(${sample})
#if(${project.propertyMap["disable.indelrealigner"]}=="yes")

#sample_realigned(${sample}) : $(call indexed_bam, #sample_merged(${sample}) )
	#just create a symbolic link
	$(call create_symbolic_link,$(filter %.bam,$^),$@)
	##ln --force -s $(filter %.bai,$^) $(addsuffix .bai,$@)

#else 

#sample_realigned(${sample}) : $(call indexed_bam, #sample_merged(${sample}) ) $(OUTDIR)/capture500.bed
		@$(call timebegindb,$@_targetcreator,targetcreator)
		$(JAVA) $(GATK.jvm) -jar $(GATK.jar) $(GATK.flags) \
			-T RealignerTargetCreator \
  			-R $(REF) \
			-L $(filter %.bed,$^) \
  			-I $(filter %.bam,$^) \
			-S SILENT \
			#if(${project.propertyMap.containsKey("gatk.realigner.target.creator.options")}
			) ${project.propertyMap.get("gatk.realigner.target.creator.options")} #end \
			-o $(addsuffix .intervals, $(filter %.bam,$^) ) \
			--known:vcfinput,VCF #if(${project.propertyMap.containsKey("known.indels.vcf")}
			 ) ${project.propertyMap.get("known.indels.vcf")} #else  
			  ${utils.error("known.indels.vcf undefined")}	 
			#end 
		@$(call timeenddb,$@_targetcreator,targetcreator)
		@$(call timebegindb,$@_indelrealigner,indelrealign)
		$(JAVA) $(GATK.jvm) -jar  $(GATK.jar) $(GATK.flags) \
  			-T IndelRealigner \
  			-R $(REF) \
  			-I $(filter %.bam,$^) \
			-S SILENT \
			#if(${project.propertyMap.containsKey("gatk.indel.realigner.options")}
			) ${project.propertyMap["gatk.indel.realigner.options"]} #end \
  			-o $@ \
  			-targetIntervals $(addsuffix .intervals, $(filter %.bam,$^) ) \
			--knownAlleles:vcfinput,VCF #if(${project.propertyMap.containsKey("known.indels.vcf")}
			 ) ${project.propertyMap["known.indels.vcf"]} #else  
			  ${utils.error("known.indels.vcf undefined")}	 
			#end 
		@$(call timeenddb,$@_indelrealigner,indelrealign)
		@$(call sizedb,$@)
		$(call notempty,$@)
		rm -f $(addsuffix .intervals, $(filter %.bam,$^) )
		$(call delete_and_touch,$(filter %.bam,$^)  )
		$(call delete_and_touch,$(filter %.bam.bai,$^)  )
		touch $@

#end

#if(${sample.sequences.pair.size()} > 1 )

#
#
# Merge all Bams for ${sample.name}
#
#
LIST_BAM_MERGED+=  #sample_merged(${sample})

#sample_merged(${sample}) : #foreach($pair in ${sample.sequences.pair} ) #pair_sorted(${pair}) #end
	
	@$(call timebegindb,$@,merge)
	$(JAVA) -jar $(PICARD)/MergeSamFiles.jar O=$@ AS=true \
		#if(${project.propertyMap.containsKey("picard.merge.options")}
			 ) ${project.propertyMap["picard.merge.options"]} #end \
		VALIDATION_STRINGENCY=SILENT \
		COMMENT="Merged from $^" \
		$(foreach B,$^, I=$(B) )
	$(DELETEFILE) $^
	@$(call timeenddb,$@,merge)
	@$(call sizedb,$@)
	$(call notempty,$@)
	$(call delete_and_touch,$^)
	touch $@
	
#end


#
# bamstats01 for sample: ${sample.name}
#
#sample_bamstat01_tsv($sample) : $(call indexed_bam, #sample_recal($sample) ) $(capture.bed)
	@$(call timebegindb,$@,bamstats01)
	mkdir -p $(dir $@)
	${VARKIT}/bamstats01 -b $(capture.bed) $(filter %.bam,$^) |\
		sed -e 's/_recal.bam//' -e "s%$(dir $(filter %.bam,$^))%%" > $@
	@$(call timeendb,$@,bamstats01)
	@$(call sizedb,$@)
	$(call notempty,$@)
	
#
# bamstats04 for sample: ${sample.name}
#
#sample_bamstat04_tsv($sample) : $(call indexed_bam, #sample_recal($sample) ) $(capture.bed)
	@$(call timebegindb,$@,bamstats04)
	mkdir -p $(dir $@)
	$(JAVA) -jar ${JVARKIT}/bamstats04.jar -b $(capture.bed) $(filter %.bam,$^) |\
		sed -e 's/_recal.bam//' -e "s%$(dir $(filter %.bam,$^))%%" > $@
	@$(call timeendb,$@,bamstats04)
	@$(call sizedb,$@)
	$(call notempty,$@)
	


<!-- distribution of coverage -->

#DISTRIBUTION_OF_COVERAGE(
	"#sample_distribution_of_coverage_recal($sample)"
	"#sample_recal($sample)"
	"depthofcovdist"
	)


#VARKIT_BEDDEDPTH(
	"#sample_beddepth($sample)"
	"#sample_recal($sample)"
	)



##############################################################################
#
# BEGIN: LOOP OVER EACH PAIR OF FASTQ for sample ${sample.name}
#


##############################################################################
#
# BEGIN PAIR ${sample.name}
#
##############################################################################


#foreach($pair in $sample.sequences.pair)


#make_bam_index("#pair_bam_sorted($pair)")



#
#
# Sort BAM 
#
LIST_BAM_SORTED+=#pair_bam_sorted($pair)

#pair_bam_sorted($pair) : #pair_bam_unsorted($pair)

	$(call timebegindb,$@,sort)
	$(SAMTOOLS) sort #if($project.propertyMap.containsKey("samtools.sort.options")
		) ${project.propertyMap["samtools.sort.options"]} #end $< $(basename $@)
	$(DELETEFILE) $<
	$(call timeenddb,$@,sort)
	$(call sizedb,$@)
	$(call notempty,$@)
	$(call delete_and_touch,$<)
	touch $@

#
# Call BWA sampe
#
#
LIST_BAM_UNSORTED+=#pair_bam_unsorted($pair)

#pair_bam_unsorted($pair) : \
	#fastq_preprocessed(${pair.forward}) \
	#fastq_preprocessed(${pair.reverse}) \
	#fastq_sai(${pair.forward}) \
	#fastq_sai(${pair.reverse}) \
	${REF}
	# ALIGN WITH BWA #################################################
	@$(call timebegindb,$@,bwasampe)
	$(BWA) sampe #if($project.propertyMap.containsKey("bwa.sampe.options")
		) ${project.propertyMap["bwa.sampe.options"]}  #else  -a 500  #end \
		-r "@RG	ID:${pair.generateId}	LB:${pair.sample.name}	SM:${pair.sample.name}	PL:ILLUMINA	PU:${pair.lane}" \
		$(REF) \
		#fastq_sai(${pair.forward}) \
		#fastq_sai(${pair.reverse}) \
		#fastq_preprocessed(${pair.forward}) \
		#fastq_preprocessed(${pair.reverse}) |\
	$(SAMTOOLS) view -S -b -o $@ -T ${REF} -
	$(DELETEFILE)  #fastq_sai(${pair.forward})  #fastq_sai(${pair.reverse}) 
	@$(call timeenddb,$@,bwasampe)
	@$(call sizedb,$@)
	@$(call notempty,$@)
	@$(call delete_and_touch,$(filter %.sai,$^))
	touch $@




##
## BEGIN : loop over the fastqs
##
#foreach($fastq in ${pair.fastq})



#fastq_sai(${fastq}) : #fastq_preprocessed($fastq) $(INDEXED_REFERENCE)
	mkdir -p $(dir $@)
	@$(call timebegindb,$@,sai)
	@$(call sizedb,$<)
	$(BWA) aln #if($project.propertyMap.containsKey("bwa.aln.options")
		) ${project.propertyMap["bwa.aln.options"]} #end \
		 -f $@ ${REF} $<
	@$(call timeenddb,$@,sai)
	@$(call sizedb,$@)
	@$(call notempty,$@)




#if($project.propertyMap["is.haloplex"]=="yes")

#
# Preprocess FASTQ
#
#fastq_preprocessed($fastq) : #fastq_raw($fastq)
	mkdir -p $(dir $@)
	@$(call timebegindb,$@,cutadapt)
	@$(call sizedb,$<)
	$(CUTADAPT) -b #if($project.propertyMap.containsKey("cutadapt.sequence.for") and $fastq.index==1
		)${project.propertyMap["cutadapt.sequence.for"]}#elseif($project.propertyMap.containsKey("cutadapt.sequence.rev") and $fastq.index==2
		)${project.propertyMap["cutadapt.sequence.rev"]}#elseif( $fastq.index==1
		)AGATCGGAAGAGCACACGTCTGAACTCCAGTCAC#elseif( $fastq.index==2
		)AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGTAGATCTCGGTGGTCGCCGTATCATT#{else
		}${utils.error("cutadapt params undefined")}#end  $< -o $(basename $@) > $(addsuffix .report.txt,$@)
	gzip --best --force $(basename $@)
	@$(call timeenddb,$@,cutadapt)
	@$(call sizedb,$@)
	$(call notempty,$@)

#end


#end

##
## END : loop over the fastq
##

##############################################################################
#
# END PAIR ${pair.index} for sample ${pair.sample.name}
#
##############################################################################

#end

##############################################################################
#
# END SAMPLES ${sample.name}
#
##############################################################################

#end


##############################################################################
# 
# END SAMPLES
#
##############################################################################




##############################################################################
#
# statistics from HSQLDB
##############################################################################

LIST_PHONY_TARGET+= hsqldb_statistics 
hsqldb_statistics: $(OUTDIR)/durations.stats.txt $(OUTDIR)/filesize.stats.txt

$(OUTDIR)/durations.stats.txt:
	lockfile $(LOCKFILE)
	mkdir -p $(dirname $(HSQLSTATS) )
	-$(JAVA) -jar ${HSQLDB.sqltool} --autoCommit --inlineRc=url=jdbc:hsqldb:file:$(HSQLSTATS) \
		--sql "select B.category$(foreach T,SECOND MINUTE HOUR DAY, ,AVG(TIMESTAMPDIFF(SQL_TSI_${T},B.W,E.W)) as duration_${T}) from begindb as B ,enddb as E where B.file=E.file group by B.category;" > $@
	rm -f $(LOCKFILE)

$(OUTDIR)/filesize.stats.txt:
	lockfile $(LOCKFILE)
	mkdir -p $(dirname $(HSQLSTATS) )
	-$(JAVA) -jar ${HSQLDB.sqltool} --autoCommit --inlineRc=url=jdbc:hsqldb:file:$(HSQLSTATS) \
		--sql "select B.category,count(*) as N, AVG(L.size) as AVG_FILESIZE from begindb as B ,sizedb as L where B.file=L.file group by B.category;" > $@
	rm -f $(LOCKFILE)

##############################################################################
#
# list target(s) for which processing has been canceled or is still
# an ongoing process.
#
LIST_PHONY_TARGET+= ongoing
ongoing:
	lockfile $(LOCKFILE)
	mkdir -p $(dirname $(HSQLSTATS) )
	-$(JAVA) -jar ${HSQLDB.sqltool} --autoCommit --inlineRc=url=jdbc:hsqldb:file:$(HSQLSTATS) \
		--sql "select B.file,B.w,E.file,E.w,B.category from begindb as B LEFT JOIN enddb as E on ( B.file=E.file and B.category=E.category ) where E.file is NULL or B.w >= E.w order by B.file ;" 
	rm -f $(LOCKFILE)	


#########################################################################################################
#
#
#
# track project changes with git
#
#
LIST_PHONY_TARGET+= git 
git:.git/config
	-git add $(makefile.name)
	-git commit -m "changes $(makefile.name)"
	
.git/config:
	git init $(dir $(makefile.name))


#
# END
#





