#
# Makefile for NGS
#
# WWW: https://github.com/lindenb/xml4ngs
#
# Date : $now
#

#parse("common.vm")
#parse("sample.vm")
#parse("fastq.vm")
#parse("pair.vm")
#parse("sample.vm")
#parse("varkit.vm")
#parse("gatk.vm")
#parse("vep.vm")
#parse("snpeff.vm")
#parse("samtools.vm")
## PROXY SETTING 
#if($project.propertyMap.containsKey("http.proxy.host")
)#set($set_curl_proxy= " --proxy "+$project.propertyMap["http.proxy.host"]+":"+$project.propertyMap["http.proxy.port"])#set($set_jvm_proxy= " -Dhttp.proxyHost="+$project.propertyMap["http.proxy.host"]+" -Dhttp.proxyPort="+$project.propertyMap["http.proxy.port"])#else#set($set_curl_proxy ="")#set($set_jvm_proxy ="")#end

#
# this is the name of the current Makefile
# should be always here,  before' include'
# will be used for 'git'
#
makefile.name := $(lastword $(MAKEFILE_LIST))

#if($project.propertyMap.containsKey("make.include"))

#
# define the path to the application
# config.mk are user-specific values
#
include ${project.propertyMap["make.include"]}

#end

############################################
#
# PROPERTIES defined in the project.xml 
#
#
#foreach($p in $project.properties.property)
# ${p.key}=${p.value.replaceAll("\n"," ")}
#end

#
# OUTPUT DIRECTORY
#

#if(! $project.propertyMap.containsKey("output.directory") )
${utils.error("output.directory' undefined in project.")}
#end
OUTDIR=$project.propertyMap["output.directory"]

#
# LIST_OF_PHONY_TARGET
#
LIST_PHONY_TARGET=


#
# LIST_OF_PHONY_TARGET
#
TOP_TARGETS=

#
# Chromosomes 
#

REF_CHROMOSOMES=#foreach($c in ${project.refChromosomes}) $c #end


ALL_CHROMOSOMES=#foreach($c in ${project.allChromosomes}) $c #end


#
# fix PATH (tophat needs this)
#
export PATH:=$(PATH):${BOWTIE2.dir}:${samtools.dir}:${CUFFLINKS.dir}:${R.dir}/bin:/usr/bin

###
# FIX LOCALE (http://unix.stackexchange.com/questions/61985)
#
export LC_ALL:=C


#
#
# path to GHOSTVIEW
GHOSTVIEW ?= gs



TABIX.bgzip?=${TABIX}/bgzip
TABIX.tabix?=${TABIX}/tabix



#if(! $project.propertyMap.containsKey("genome.reference.path") )
${utils.error("genome.reference.path' undefined in project.")}
#end

#
# reference genome was set in project properties
#
REF=$project.propertyMap["genome.reference.path"]
INDEXED_REFERENCE=$(foreach S,.amb .ann .bwt .pac .sa .fai,$(addsuffix $S,$(REF))) $(addsuffix	.dict,$(basename $(REF)))

#
# min mapping quality
#
#if(! $project.propertyMap.containsKey("min.mapping.quality") )
${utils.warning("'min.mapping.quality' undefined in project, will use: 30")}
MIN_MAPPING_QUALITY=30
#else
MIN_MAPPING_QUALITY=$project.propertyMap["min.mapping.quality"]
#end



#
# file that will be used to lock the SQL-related resources
#
LOCKFILE=$(OUTDIR)/_tmp.${project.generateId}.lock
HSQLSTATS=$(OUTDIR)/HSQLDB/hsqldb.stats




SAMPLES=#foreach($sample in $project.sample)${sample.name} #end


#if(! $project.propertyMap.containsKey("capture.bed.path") )
${utils.warning("'capture.bed.path' undefined in project.")}
capture.bed=$(OUTDIR)/BED/ensembl.exons.bed
#else
capture.bed=${project.propertyMap["capture.bed.path"]}
#end


#
# extended capture
# 
extended_capture_bed=$(OUTDIR)/BED/capture500.bed

#if(! $project.propertyMap.containsKey("known.sites") )
${utils.error("'known.sites' undefined in project.")}
#else
known.sites=${project.propertyMap["known.sites"]}
#end


#
# TARGETS AS LISTS
#

##########################################################################################################
#
# PHONY TARGETS
#
#
.PHONY: all toptarget ${LIST_PHONY_TARGET} 

##########################################################################################################
#
# MACRO DEFINITIONS
#
#
ifndef DELETEFILE
DELETEFILE=echo 
endif

define bai_files
    $(foreach B,$(filter %.bam,$(1)),  $(patsubst %.bam,%.bai,$B) )
endef


define indexed_bam
    $(1) $(call bai_files, $(1))
endef

define create_symbolic_link
	cp -f $(1) $(2)
endef

define notempty
    test -s $(1) || (echo "$(1) is empty" && rm -f $(1) && exit -1) 
endef

define check_no_sge
	if  [ "${JOB_ID}" != "" ]; then echo "This process shouldn't be run with SGE. Please invoke the regular make." ; exit -1;  fi
endef



CREATE_HSQLDB_DATABASE=create table if not exists begindb(file varchar(255) not null,category varchar(255) not null,w TIMESTAMP,CONSTRAINT K1 UNIQUE (file,category));create table if not exists enddb(file varchar(255) not null,category varchar(255) not null,w TIMESTAMP,CONSTRAINT K2 UNIQUE (file,category));create table if not exists sizedb(file varchar(255) not null,size BIGINT,CONSTRAINT K3 UNIQUE (file));

define timebegindb
	lockfile $(LOCKFILE)
	mkdir -p $(dir $(HSQLSTATS))
	$(JAVA) -jar $(HSQLDB.sqltool) --autoCommit --inlineRc=url=jdbc:hsqldb:file:$(HSQLSTATS) --sql "$(CREATE_HSQLDB_DATABASE) delete from begindb where file='$(1)' and category='$(2)'; insert into begindb(file,category,w) values ('$(1)','$(2)',NOW);"
	rm -f $(LOCKFILE)
endef

define timeenddb
	lockfile $(LOCKFILE)
	mkdir -p $(dir $(HSQLSTATS))
	$(JAVA) -jar ${HSQLDB.sqltool} --autoCommit --inlineRc=url=jdbc:hsqldb:file:$(HSQLSTATS) --sql "$(CREATE_HSQLDB_DATABASE) delete from enddb where file='$(1)' and category='$(2)'; insert into enddb(file,category,w) values ('$(1)','$(2)',NOW);"
	rm -f $(LOCKFILE)
endef


define sizedb
	mkdir -p $(dir $(HSQLSTATS))
	stat -c "%s" $(1) | while read L; do lockfile $(LOCKFILE); $(JAVA) -jar ${HSQLDB.sqltool} --autoCommit --inlineRc=url=jdbc:hsqldb:file:$(HSQLSTATS) --sql "$(CREATE_HSQLDB_DATABASE) delete from sizedb where file='$(1)'; insert into sizedb(file,size) values('$(1)','$$L');" ; rm -f $(LOCKFILE);done
endef




define delete_and_touch
	
endef

##########################################################################################################
#
# PATTERN RULES DEFINITIONS
#
#


# 
# create BAM index for ${bam}
#
%.bai : %.bam
	@$(call timebegindb,$@,bai)
	#some indexes are created by picard, no need to recreate it, or just check the timestamp
	if [ ! -f "$@" ] || [ "$@" -ot  "$<" ] ; then $(SAMTOOLS) index $< $@; else echo "OK. $< already indexed."; fi
	@$(call timeenddb,$@,bai)
	@$(call sizedb,$@)
	$(call notempty,$@)

#macro(call_index_genome_rules $extension)


#index with bwa
%.amb %.ann %.bwt %.pac %.sa : %$extension
	$(BWA) index -a bwtsw $<

#index with samtools
${extension}.fai : %$extension
	$(SAMTOOLS) faidx $<

#picard dictionnary
%.dict: %${extension}
	 $(JAVA) -jar $(PICARD)/CreateSequenceDictionary.jar \
		R=$< \
		O=$@ \
		GENOME_ASSEMBLY=$(basename $(notdir $<)) \
		TRUNCATE_NAMES_AT_WHITESPACE=true

#end
#call_index_genome_rules(".fa")
#call_index_genome_rules(".fasta")

#
# treat all files as SECONDARY
#
.SECONDARY :



toptarget:
	@echo "This is the top target. Please select a specific target"
	@echo "e.g: ${TOP_TARGETS} "

all: ${TOP_TARGETS} all_predictions fastx hsqldb_statistics 









LIST_PHONY_TARGET+= coverage
TOP_TARGETS+= coverage

coverage:$(OUTDIR)/Statistics/mean_coverage01.pdf
$(OUTDIR)/Statistics/mean_coverage01.pdf: $(addsuffix .sample_summary, #foreach($sample in $project.sample) #sample_coverage($sample) #end)
	mkdir -p $(dir $@)
	echo "sample	mean-coverage" > $(patsubst %.pdf,%.tsv,$@)
	cat $^ | sort | grep -v -E  '^(Total|sample_id)'  |\
		cut -d '	' -f1,3 >> $(patsubst %.pdf,%.tsv,$@)
	echo 'pdf("$@",paper="A4r"); T<-read.table("$(patsubst %.pdf,%.tsv,$@)",header=T,sep="\t",row.names=1); barplot(as.matrix(t(T)),legend=colnames(T),beside=TRUE,col=rainbow(7),las=2,cex.names=0.8); dev.off()' |\
	${R.exe} --no-save
	



############################################################################################
#
# ALLELES CALLING
#
#




#set( $genotypeMethods = ["samtools", "gatk"] )
#set( $annotationMethods = ["snpeff", "vep"] )
 

#if( $project.getPropertyByName("one.vcf.per.sample","no")=="yes")

LIST_PHONY_TARGET+= all_predictions
TOP_TARGETS+= all_predictions
all_predictions: #foreach($genotyper in $genotypeMethods) variations.${genotyper} #foreach($annotator in $annotationMethods) variations.${genotyper}.${annotator} #end #end


#foreach($genotyper in $genotypeMethods)

LIST_PHONY_TARGET+= variations.${genotyper}
TOP_TARGETS+= variations.${genotyper}

variations.${genotyper} : #foreach($sample in $project.sample) #sample_vcf_genotyper($sample $genotyper) #end


#foreach($annotator in $annotationMethods)

LIST_PHONY_TARGET+= variations.${genotyper}.${annotator}
TOP_TARGETS+= variations.${genotyper}.${annotator}
variations.${genotyper}.${annotator} : #foreach($sample in $project.sample) #sample_vcf_genotyper_annotator($sample $genotyper ${annotator} ) #end

## END LOOP OVER ANNOTATOR

#end

## END LOOP OVER GENOTYPER

#end 




#foreach($sample in $project.sample)
#foreach($genotyper in $genotypeMethods)




# 
# merge all the chromosomes for sample ${sample.name}
#

#sample_vcf_genotyper($sample $genotyper) : #foreach($c in ${project.allChromosomes}) #sample_vcf_genotyper_chrom($sample $genotyper $c) #end
	
	mkdir -p $(dir $@)
	perl -I $(VCFTOOLS.dir)/perl $(VCFTOOLS.dir)/perl/vcf-concat $^ |\
	perl -I $(VCFTOOLS.dir)/perl $(VCFTOOLS.dir)/perl/vcf-sort |\
	$(TABIX.bgzip) -c > $@ 
	$(TABIX.tabix) -f -p vcf $@
	

#foreach($c in ${project.allChromosomes})

#sample_vcf_genotyper_chrom($sample $genotyper $c): #sample_final_bam( ${sample} ) #if(${project.getPropertyByName("allele.calling.in.capture","no")}=="yes") $(extended_capture_bed) #end

#if( $genotyper == "samtools")
#call_with_samtools_mpileup()

#elseif( $genotyper == "gatk")
#call_with_gatk()

#else

${utils.error("unknown genotyper [${genotyper}]")}

## end if genotyper

#end 

## end for-each chromosomes

#end



#foreach($annotator in $annotationMethods)

#
# predictions ${genotyper} with ${annotator} for  sample ${sample.name}
#

#set($genotyperfilterproperty=${genotyper}+".vcf.filtration")
#set($annotatorfilterproperty=${annotator}+".vcf.filtration")
#set($filterparam=${project.getPropertyByName($genotyperfilterproperty,"")}+" "+${project.getPropertyByName($annotatorfilterproperty,"")})


#if( $annotator == "vep")

#annotate_with_vep(
	"#sample_vcf_genotyper_annotator($sample $genotyper ${annotator} )"
	"#sample_vcf_genotyper($sample $genotyper) "
	"${genotyper}${annotator}"
	"$filterparam"
	)

#elseif(  $annotator == "snpeff" )

#annotate_with_snpeff(
	"#sample_vcf_genotyper_annotator($sample $genotyper ${annotator} )"
	"#sample_vcf_genotyper($sample $genotyper) "
	"${genotyper}${annotator}"
	"$filterparam"
	)

#else

${utils.error("unknown annotator [${annotator}]")}

#end

#end

#end

#end

## end for each sample

#else

LIST_PHONY_TARGET+=all_predictions
TOP_TARGETS+=all_predictions

all_predictions: #foreach($genotyper in $genotypeMethods) $(OUTDIR)/VCF/variations.${genotyper}.vcf.gz #foreach($annotator in $annotationMethods) $(OUTDIR)/VCF/variations.${genotyper}.${annotator}.vcf.gz  #end #end
	

#foreach($genotyper in $genotypeMethods)

#
# Create VCF for all samples with ${genotyper} 
#

TOP_TARGETS+= $(OUTDIR)/VCF/variations.${genotyper}.vcf.gz 

$(OUTDIR)/VCF/variations.${genotyper}.vcf.gz : #foreach($sample in ${project.sample}) #sample_final_bam( ${sample} ) #end \
		#if(${project.getPropertyByName("allele.calling.in.capture","no")}=="yes") $(extended_capture_bed) #end
	
#if( $genotyper == "samtools")
#call_with_samtools_mpileup()

#elseif( $genotyper == "gatk")
#call_with_gatk()

#else

${utils.error("unknown genotyper [${genotyper}]")}

## end if genotyper

#end 

#foreach($annotator in $annotationMethods)

#set($genotyperfilterproperty=${genotyper}+".vcf.filtration")
#set($annotatorfilterproperty=${annotator}+".vcf.filtration")
#set($filterparam=${project.getPropertyByName($genotyperfilterproperty,"")}+" "+${project.getPropertyByName($annotatorfilterproperty,"")})


#if( $annotator == "vep")
#annotate_with_vep(
	"$(OUTDIR)/VCF/variations.${genotyper}.${annotator}.vcf.gz"
	"$(OUTDIR)/VCF/variations.${genotyper}.vcf.gz "
	"${genotyper}${annotator}"
	"$filterparam"
	)

#elseif(  $annotator == "snpeff" )
#annotate_with_snpeff(
	"$(OUTDIR)/VCF/variations.${genotyper}.${annotator}.vcf.gz"
	"$(OUTDIR)/VCF/variations.${genotyper}.vcf.gz "
	"${genotyper}${annotator}"
	"$filterparam"
	)

#else

${utils.error("unknown annotator [${annotator}]")}

#end


## enf of loop over annotator

#end

## enf of loop over genotypers

#end


#end


############################################################################################
#
# Statistics for BAM
#
LIST_PHONY_TARGET+= bam_statistics 
TOP_TARGETS+= bam_statistics 

bam_statistics: $(OUTDIR)/Statistics/#output_files_prefix()bamstats01.pdf \
	$(OUTDIR)/Statistics/#output_files_prefix()bamstats03.pdf \
	$(OUTDIR)/Statistics/#output_files_prefix()bamstats04.tsv \
	beddepth coverage_distribution 


LIST_PHONY_TARGET+= beddepth
TOP_TARGETS+= beddepth
beddepth:  #foreach($sample in $project.sample) #sample_beddepth(${sample}) #end


#
# create a PDF for bamstats01.tsv
#
TOP_TARGETS+= $(OUTDIR)/Statistics/#output_files_prefix()bamstats01.pdf

$(OUTDIR)/Statistics/#output_files_prefix()bamstats01.pdf : $(OUTDIR)/Statistics/#output_files_prefix()bamstats01.tsv
	mkdir -p $(dir $@)
	echo 'pdf("$@",paper="A4r"); T<-read.delim("$<",header=T,sep="\t",row.names=1);barplot(as.matrix(t(T)),beside=TRUE,col=rainbow(8),las=2,cex.names=0.8,legend=colnames(T)); dev.off()' |\
	${R.exe} --no-save

#
# count of mapped-reads	
#
$(OUTDIR)/Statistics/#output_files_prefix()bamstats01.tsv : #foreach($sample in $project.sample) #sample_bamstat01_tsv($sample) #end

	mkdir -p $(dir $@)
	cat $^ |  LC_ALL=C sort -t '	' -k1,1 | uniq > $@


#
# count of distribution of coverage
#

TOP_TARGETS+= $(OUTDIR)/Statistics/#output_files_prefix()bamstats04.tsv

$(OUTDIR)/Statistics/#output_files_prefix()bamstats04.tsv : #foreach($sample in $project.sample)  #sample_bamstat04_tsv($sample) #end

	mkdir -p $(dir $@)
	cat $^ |  LC_ALL=C sort -t '	' -k1,1 | uniq > $@




## coverage of distribution ############################################################################################

LIST_PHONY_TARGET+= coverage_distribution
TOP_TARGETS+= coverage_distribution

coverage_distribution:  $(OUTDIR)/Statistics/#output_files_prefix()all.distribution.recal.pdf



$(OUTDIR)/Statistics/#output_files_prefix()all.distribution.recal.pdf : #foreach($sample in $project.sample) #sample_distribution_of_coverage_recal($sample) #end

	gs -dBATCH -dNOPAUSE -q -sDEVICE=pdfwrite -sOutputFile=$@ $(filter %.pdf,$^)


#
# create a PDF for bamstats03.tsv
#
$(OUTDIR)/Statistics/#output_files_prefix()bamstats03.pdf : $(OUTDIR)/Statistics/#output_files_prefix()bamstats03.tsv
	mkdir -p $(dir $@)
	echo 'pdf("$@",paper="A4r"); T<-read.delim("$<",header=T,sep="\t",row.names=1);barplot(as.matrix(t(T)),beside=TRUE,col=rainbow(7),las=2,cex.names=0.8,legend=colnames(T)); dev.off()' |\
	${R.exe} --no-save

#
# count of mapped-reads, quality per sample	
#
$(OUTDIR)/Statistics/#output_files_prefix()bamstats03.tsv : $(call indexed_bam,#foreach($sample in $project.sample) #sample_final_bam($sample) #end)  $(capture.bed) 
	@$(call timebegindb,$@,$@)
	mkdir -p $(dir $@)
	${VARKIT}/bamstats03 -b $(capture.bed) $(filter %.bam,$^) | awk -F '/' '{print $$NF;}'  | sort  > $@
	@$(call timeendb,$@,$@)
	@$(call sizedb,$@)
	$(call notempty,$@)


##############################################################"
#
# Capture
#

$(OUTDIR)/BED/ensembl.exons.bed:
	$(call timebegindb,$@,$@)
	mkdir -p $(dir $@)
	curl ${set_curl_proxy} -d 'query=<?xml version="1.0" encoding="UTF-8"?><Query virtualSchemaName="default" formatter="TSV" header="0" uniqueRows="0" count="" datasetConfigVersion="0.6" ><Dataset name="#if($project.propertyMap.containsKey["ensembl.dataset.name"])
		)${project.propertyMap["ensembl.dataset.name"]}#{else}hsapiens_gene_ensembl#end" interface="default" ><Attribute name="chromosome_name" /><Attribute name="exon_chrom_start" /><Attribute name="exon_chrom_end" /></Dataset></Query>'  "http://www.biomart.org/biomart/martservice/result" |\
	grep -v '_' |grep -v 'GL' |grep -v 'MT' |\
	awk -F '	' '(int($$2) < int($$3))' |\
	uniq | LC_ALL=C sort -t '	' -k1,1 -k2,2n -k3,3n |\
	$(BEDTOOLS)/mergeBed -i - | uniq > $@
	$(call timeendb,$@,$@)
	$(call sizedb,$@)
	$(call notempty,$@)


#
# extends the bed by 500 by default
#
ifndef extend.bed
extend.bed=500
endif


#
# an extended version of the capture, will be used for recalibration
#
$(extended_capture_bed): $(capture.bed)
	mkdir -p $(dir $@)
	cut -d '	' -f1,2,3 $< |\
	awk -F '	'  -v x=$(extend.bed) '{S=int($$2)-int(x); if(S<0) S=0; printf("%s\t%d\t%d\n",$$1,S,int($$3)+int(x));}' |\
	sort -t '	' -k1,1 -k2,2n -k3,3n |\
	$(BEDTOOLS)/mergeBed -d $(extend.bed) -i - > $@
	$(call notempty,$@)


##############################################################################
#
# BEGIN SAMPLES
#
##############################################################################
#foreach($sample in $project.sample)


##############################################################################
#
# BEGIN SAMPLES ${sample.name}
#
##############################################################################


#
# Depth of coverage with GATK
#

LIST_PHONY_TARGET+= ${sample.name}_coverage_with_gatk 

$(addprefix #sample_coverage($sample), .sample_cumulative_coverage_counts .sample_cumulative_coverage_proportions .sample_interval_statistics .sample_interval_summary .sample_statistics .sample_summary) : ${sample.name}_coverage_with_gatk


${sample.name}_coverage_with_gatk  : $(call indexed_bam, #sample_final_bam( ${sample} ) ) $(capture.bed)
	$(call timebegindb,#sample_coverage(${sample}),coverage.gatk)
	mkdir -p $(dir $@)
	$(JAVA) $(GATK.jvm) -jar $(GATK.jar) $(GATK.flags) \
		-R $(REF) \
		-T DepthOfCoverage \
		-L:capture,BED $(filter %.bed,$^) \
		-S SILENT \
		--minMappingQuality $(MIN_MAPPING_QUALITY) \
		--summaryCoverageThreshold 5 \
		-I $(filter %.bam,$^) \
		-o #sample_coverage(${sample}) \
		-omitBaseOutput
	$(call timeendb,#sample_coverage(${sample}),coverage.gatk)





#
# make TOP bam, merging all chromosomes
#

#sample_final_bam(${sample}) : #foreach($chrom in ${project.allChromosomes}) #sample_recal_chrom( ${sample} ${chrom})  #end
	
	@$(call timebegindb,$@,merge_chroms)
	mkdir -p $(dir $@)	
	$(JAVA) -jar $(PICARD)/MergeSamFiles.jar O=$@ SO=coordinate AS=true \
		#if(${project.propertyMap.containsKey("picard.merge.options")}
			 ) ${project.getPropertyByName("picard.merge.options","")} #end \
		CREATE_INDEX=true \
		VALIDATION_STRINGENCY=SILENT \
		COMMENT="Merged from $^" \
		$(foreach B,$^, I=$(B) )
	$(DELETEFILE) $^
	@$(call timeenddb,$@,merge_chroms)
	@$(call sizedb,$@)
	$(call notempty,$@)
	$(call delete_and_touch,$^)
	touch $@




#if( ${project.getPropertyByName("disable.recalibration","no")}!="yes")
#foreach($chrom in ${project.allChromosomes})
#
#
# Recalibrate alignments for Sample ${sample.name}
#
#
LIST_BAM_RECAL+=#sample_recal_chrom( ${sample} ${chrom})


	
#sample_recal_chrom( ${sample} ${chrom})  : $(call indexed_bam, #sample_markdup_chrom(${sample} ${chrom}) ) \
		$(extended_capture_bed) \
		$(known.sites) \
		$(addsuffix .recal_data.grp,#sample_recal_chrom( ${sample} ${chrom}) )
	@$(call timebegindb,$@_tableRecalibaration,recalibration)
	mkdir -p $(dir $@)
	$(JAVA) $(GATK.jvm) -jar $(GATK.jar) $(GATK.flags) \
		-T PrintReads \
		-R $(REF) \
		-BQSR $(filter %.grp,$^) \
		-I $(filter %.bam,$^) \
		#if( $project.propertyMap.containsKey("gatk.recalibration.print.reads.options")
			) ${project.getPropertyByName("gatk.recalibration.print.reads.options","")} #end \
		-o $@ \
		--validation_strictness LENIENT \
		-l INFO
	@$(call timeenddb,$@_tableRecalibaration,recalibration)
	@$(call sizedb,$@)
	$(call notempty,$@)
	touch $@


$(addsuffix .recal_data.grp,#sample_recal_chrom( ${sample} ${chrom}) )   : $(call indexed_bam, #sample_markdup_chrom(${sample} ${chrom}) ) \
			$(extended_capture_bed) \
			$(known.sites)
	@$(call timebegindb,#sample_recal_chrom(${sample} ${chrom}),covariates)
	mkdir -p $(dir $@)
	$(JAVA) $(GATK.jvm) -jar $(GATK.jar) $(GATK.flags) \
		-T BaseRecalibrator \
		--validation_strictness LENIENT \
		-R $(REF) \
		-I $(filter %.bam,$^) \
		-l INFO \
		#if( $project.propertyMap.containsKey("gatk.base.recalibrator.options")
			) ${project.getPropertyByName("gatk.base.recalibrator.options","")} #end \
		-o $@ \
		-knownSites:vcfinput,VCF $(known.sites) \
		-L:capture,BED $(filter %.bed,$^) \
		-cov ReadGroupCovariate \
		-cov QualityScoreCovariate \
		-cov CycleCovariate \
		-cov ContextCovariate
	@$(call timeenddb,#sample_recal_chrom(${sample} ${chrom}),covariates)

#end
#end




#if(!(${project.getPropertyByName("disable.mark.duplicates","no")}=="yes" || ${project.getPropertyByName("is.haloplex","no")}=="yes"))
#foreach($chrom in ${project.allChromosomes})

#
#
# Mark duplicates for Sample: ${sample.name}
#


#sample_markdup_chrom(${sample}) : $(call indexed_bam, #sample_realigned_chrom(${sample} ${chrom}) )
#if( ${project.getPropertyByName("use.samtools.rmdup","no")} == "yes" )	@$(call timebegindb,$@_markdup,markdup)
	mkdir -p $(dir $@)
	$(SAMTOOLS) rmdup $(filter %.bam,$^) $@
	$(call sizedb,$@)
	$(call notempty,$@)
	$(call delete_and_touch,$(filter %.bam,$^) )
	$(call delete_and_touch,$(filter %.bai,$^) )

#else	$(call timebegindb,$@_markdup,markdup)
	mkdir -p $(dir $@)
	mkdir -p $(addsuffix tmp.rmdup,$(dir $@))
	$(JAVA) $(PICARD.jvm) -jar $(PICARD)/MarkDuplicates.jar \
		TMP_DIR=$(addsuffix tmp.rmdup,$(dir $@)) \
		INPUT=$(filter %.bam,$^) \
		O=$@ \
		MAX_FILE_HANDLES=400 \
		M=$@.metrics \
		AS=true \
		#if(${project.propertyMap.containsKey("picard.mark.duplicates.options")}
			) ${project.propertyMap.get("picard.mark.duplicates.options")} #end \
		VALIDATION_STRINGENCY=SILENT
	@$(call timeenddb,$@_markdup,markdup)
	@$(call sizedb,$@)
	$(call notempty,$@)
	$(call delete_and_touch,$(filter %.bam,$^) )
	$(call delete_and_touch,$(filter %.bai,$^) )
	touch $@

#end

#end
#end


#if(${project.getPropertyByName("disable.indelrealigner","no")}!="yes")
#foreach($chrom in ${project.allChromosomes})

#
#
# IndelRealignments for Sample ${sample.name}
#
#


#sample_realigned_chrom(${sample} ${chrom}) :	$(call indexed_bam, #sample_merged_chrom(${sample} ${chrom}) ) \
				$(addsuffix .intervals,#sample_merged_chrom(${sample} ${chrom})) \
				$(extended_capture_bed) 		
		@$(call timebegindb,$@_indelrealigner,indelrealign)
		mkdir -p $(dir $@)
		$(JAVA) $(GATK.jvm) -jar  $(GATK.jar) $(GATK.flags) \
  			-T IndelRealigner \
  			-R $(REF) \
  			-I $(filter %.bam,$^) \
			#if(${project.propertyMap.containsKey("gatk.indel.realigner.options")}
			) ${project.propertyMap["gatk.indel.realigner.options"]} #end \
  			-o $@ \
  			-targetIntervals $(filter %.intervals,$^)  \
			--knownAlleles:vcfinput,VCF #if(${project.propertyMap.containsKey("known.indels.vcf")}
			 ) ${project.getPropertyByName("known.indels.vcf","")} #else  
			  ${utils.error("known.indels.vcf undefined")}	 
			#end \
			-S SILENT 
		@$(call timeenddb,$@_indelrealigner,indelrealign)
		@$(call sizedb,$@)
		$(call notempty,$@)
		$(call delete_and_touch,$(filter %.bam,$^)  )
		$(call delete_and_touch,$(filter %.bam.bai,$^)  )
		touch $@


$(addsuffix .intervals,#sample_merged_chrom(${sample} ${chrom})) : $(call indexed_bam, #sample_merged_chrom(${sample} ${chrom}) ) $(extended_capture_bed)
		@$(call timebegindb,$@_targetcreator,targetcreator)
		mkdir -p $(dir $@)
		$(JAVA) $(GATK.jvm) -jar $(GATK.jar) $(GATK.flags) \
			-T RealignerTargetCreator \
  			-R $(REF) \
			-L:capture,BED $(filter %.bed,$^) \
  			-I $(filter %.bam,$^) \
			#if(${project.propertyMap.containsKey("gatk.realigner.target.creator.options")}
			) ${project.propertyMap.get("gatk.realigner.target.creator.options")} #end \
			-o $(addsuffix .intervals, $(filter %.bam,$^) ) \
			--known:vcfinput,VCF #if(${project.propertyMap.containsKey("known.indels.vcf")}
			 ) ${project.getPropertyByName("known.indels.vcf","")} #else  
			  ${utils.error("known.indels.vcf undefined")}	 
			#end \
			-S SILENT 
		@$(call timeenddb,$@_targetcreator,targetcreator)


#end
#end

#if( ${sample.sequences.pair.size()} > 1)
#foreach($chrom in ${project.allChromosomes})

#
#
# Merge all Bams for ${sample.name} for chromosome ${chrom}
#
#
LIST_BAM_MERGED+=  #sample_merged_chrom(${sample} ${chrom})

#sample_merged_chrom(${sample} ${chrom}) : #foreach($pair in ${sample.sequences.pair} ) #pair_bam_sorted_chrom(${pair} ${chrom}) #end
	
	@$(call timebegindb,$@,merge)
	mkdir -p $(dir $@)	
	$(JAVA) -jar $(PICARD)/MergeSamFiles.jar O=$@ SO=coordinate AS=true \
		#if(${project.propertyMap.containsKey("picard.merge.options")}
			 ) ${project.getPropertyByName("picard.merge.options","")} #end \
		CREATE_INDEX=true \
		VALIDATION_STRINGENCY=SILENT \
		COMMENT="Merged for chromosome ${chrom} from $^" \
		$(foreach B,$^, I=$(B) )
	$(DELETEFILE) $^
	@$(call timeenddb,$@,merge)
	@$(call sizedb,$@)
	$(call notempty,$@)
	$(call delete_and_touch,$^)
	touch $@
	
#end
#end

#
# bamstats01 for sample: ${sample.name}
#
#sample_bamstat01_tsv($sample) : $(call indexed_bam, #sample_recal($sample) ) $(capture.bed)
	@$(call timebegindb,$@,bamstats01)
	mkdir -p $(dir $@)
	${VARKIT}/bamstats01 -b $(capture.bed) $(filter %.bam,$^) |\
		sed -e 's/_recal.bam//' -e "s%$(dir $(filter %.bam,$^))%%" > $@
	@$(call timeendb,$@,bamstats01)
	@$(call sizedb,$@)
	$(call notempty,$@)
	
#
# bamstats04 for sample: ${sample.name}
#
#sample_bamstat04_tsv($sample) : $(call indexed_bam, #sample_recal($sample) ) $(capture.bed)
	@$(call timebegindb,$@,bamstats04)
	mkdir -p $(dir $@)
	$(JAVA) -jar ${JVARKIT}/bamstats04.jar -b $(capture.bed) $(filter %.bam,$^) |\
		sed -e 's/_recal.bam//' -e "s%$(dir $(filter %.bam,$^))%%" > $@
	@$(call timeendb,$@,bamstats04)
	@$(call sizedb,$@)
	$(call notempty,$@)
	




#DISTRIBUTION_OF_COVERAGE(
	"#sample_distribution_of_coverage_recal($sample)"
	"#sample_recal($sample)"
	"depthofcovdist"
	)


#VARKIT_BEDDEDPTH(
	"#sample_beddepth($sample)"
	"#sample_recal($sample)"
	)



##############################################################################
#
# BEGIN: LOOP OVER EACH PAIR OF FASTQ for sample ${sample.name}
#


##############################################################################
#
# BEGIN PAIR ${sample.name}
#
##############################################################################


#foreach($pair in $sample.sequences.pair)



#
# Call BWA sampe
#
#

LIST_PHONY_TARGET+=${sample.name}_sampe_chromosomes

#foreach($c in ${project.allChromosomes})#pair_bam_sorted_chrom($pair $c ) #end : ${sample.name}_sampe_pair${pair.index}_chromosomes


${sample.name}_sampe_pair${pair.index}_chromosomes : \
	#fastq_preprocessed(${pair.forward}) \
	#fastq_preprocessed(${pair.reverse}) \
	#fastq_sai(${pair.forward}) \
	#fastq_sai(${pair.reverse}) \
	${REF}
	@$(call timebegindb,$@,bwasampe)
	mkdir -p #sample_BAM(${pair.sample})
	
	$(BWA) sampe #if($project.propertyMap.containsKey("bwa.sampe.options")
		) ${project.propertyMap["bwa.sampe.options"]}  #else  -a 500  #end \
		-r "@RG	ID:${pair.generateId}	LB:${pair.sample.name}	SM:${pair.sample.name}	PL:ILLUMINA	PU:${pair.lane}" \
		$(REF) \
		#fastq_sai(${pair.forward}) \
		#fastq_sai(${pair.reverse}) \
		#fastq_preprocessed(${pair.forward}) \
		#fastq_preprocessed(${pair.reverse}) |\
		$(JAVA) -jar $(JVARKIT)/splitbam.jar --mock -R ${REF} -p '#pair_bam_sorted_chrom($pair "__CHROM__" )'  --tmp #sample_BAM(${pair.sample}) --index -u Unmapped
	$(DELETEFILE)  #fastq_sai(${pair.forward})  #fastq_sai(${pair.reverse}) 
	
	@$(call timeenddb,$@,bwasampe)
	@$(call delete_and_touch,$(filter %.sai,$^))




##
## BEGIN : loop over the fastqs
##
#foreach($fastq in ${pair.fastq})



#fastq_sai(${fastq}) : #fastq_preprocessed($fastq) $(REF)
	mkdir -p $(dir $@)
	@$(call timebegindb,$@,sai)
	@$(call sizedb,$<)
	$(BWA) aln #if($project.propertyMap.containsKey("bwa.aln.options")
		) ${project.getPropertyByName("bwa.aln.options","")} #end \
		 -f $@ \
		 $(REF) \
		 $<
	@$(call timeenddb,$@,sai)
	@$(call sizedb,$@)
	@$(call notempty,$@)




#if(${project.getPropertyByName("is.haloplex","no")}=="yes")

#
# Preprocess FASTQ
#
#fastq_preprocessed($fastq) : #fastq_raw($fastq)

	mkdir -p $(dir $@)
	@$(call timebegindb,$@,cutadapt)
	@$(call sizedb,$<)
	$(CUTADAPT) -b #if($project.propertyMap.containsKey("cutadapt.sequence.for") && ${fastq.index}==1
		)${project.propertyMap["cutadapt.sequence.for"]}#elseif(
		$project.propertyMap.containsKey("cutadapt.sequence.rev") &&  ${fastq.index}==2
		)${project.propertyMap["cutadapt.sequence.rev"]}#elseif(
		${fastq.index}==1)AGATCGGAAGAGCACACGTCTGAACTCCAGTCAC#elseif(
		${fastq.index}==2)AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGTAGATCTCGGTGGTCGCCGTATCATT#else${utils.warning("cutadapt params undefined for ${fastq} index=${fastq.index}")}#end  $< -o $(basename $@) > $(addsuffix .report.txt,$@)
	gzip --best --force $(basename $@)
	@$(call timeenddb,$@,cutadapt)
	@$(call sizedb,$@)
	$(call notempty,$@)

#end


#end

##
## END : loop over the fastq
##

##############################################################################
#
# END PAIR ${pair.index} for sample ${pair.sample.name}
#
##############################################################################

#end

##############################################################################
#
# END SAMPLES ${sample.name}
#
##############################################################################

#end


##############################################################################
# 
# END SAMPLES
#
##############################################################################




##############################################################################
#
# statistics from HSQLDB
##############################################################################

LIST_PHONY_TARGET+= hsqldb_statistics 

TOP_TARGETS+= hsqldb_statistics 

hsqldb_statistics: $(OUTDIR)/durations.stats.txt $(OUTDIR)/filesize.stats.txt

$(OUTDIR)/durations.stats.txt:
	lockfile $(LOCKFILE)
	mkdir -p $(dir $(HSQLSTATS) )
	-$(JAVA) -jar ${HSQLDB.sqltool} --autoCommit --inlineRc=url=jdbc:hsqldb:file:$(HSQLSTATS) \
		--sql "select B.category$(foreach T,SECOND MINUTE HOUR DAY, ,AVG(TIMESTAMPDIFF(SQL_TSI_${T},B.W,E.W)) as duration_${T}) from begindb as B ,enddb as E where B.file=E.file group by B.category;" > $@
	rm -f $(LOCKFILE)

$(OUTDIR)/filesize.stats.txt:
	lockfile $(LOCKFILE)
	mkdir -p $(dir $(HSQLSTATS) )
	-$(JAVA) -jar ${HSQLDB.sqltool} --autoCommit --inlineRc=url=jdbc:hsqldb:file:$(HSQLSTATS) \
		--sql "select B.category,count(*) as N, AVG(L.size) as AVG_FILESIZE from begindb as B ,sizedb as L where B.file=L.file group by B.category;" > $@
	rm -f $(LOCKFILE)

##############################################################################
#
# list target(s) for which processing has been canceled or is still
# an ongoing process.
#
LIST_PHONY_TARGET+= ongoing

TOP_TARGETS+= ongoing

ongoing:
	lockfile $(LOCKFILE)
	mkdir -p $(dir $(HSQLSTATS) )
	-$(JAVA) -jar ${HSQLDB.sqltool} --autoCommit --inlineRc=url=jdbc:hsqldb:file:$(HSQLSTATS) \
		--sql "select B.file,B.w,E.file,E.w,B.category from begindb as B LEFT JOIN enddb as E on ( B.file=E.file and B.category=E.category ) where E.file is NULL or B.w >= E.w order by B.file ;" 
	rm -f $(LOCKFILE)	


#########################################################################################################
#
#
#
# track project changes with git
#
#
LIST_PHONY_TARGET+= git 
TOP_TARGETS+= git

git:.git/config
	-git add $(makefile.name)
	-git commit -m "changes $(makefile.name)"
	
.git/config:
	git init $(dir $(makefile.name))

#parse("contaminations.vm")

#
# END
#





